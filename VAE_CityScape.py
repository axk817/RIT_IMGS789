# -*- coding: utf-8 -*-
"""VAE_Cityscape.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WrBr-YqdAYD-mZ3ft7Qqoy1sAitlfrED?resourcekey=0-rhSaBAtlryhJnM9M7A9wqw
"""

pip install scikit-image

import os
import random
import zipfile
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr  # Import PSNR
from skimage.metrics import structural_similarity as ssim  # Import SSIM
from google.colab import drive
drive.mount('/content/drive')

# Path to the downloaded zip file
zip_filepath = "/content/drive/MyDrive/leftImg8bit_trainvaltest.zip"

#Routine to load the images, resize and do data augmentation
def load_cityscapes_images(zip_filepath, folder, num_images=4000):
    images = []
    count = 0

    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:
        for filename in zip_ref.namelist():
            # Check if the file is in the specified folder and ends with '.png'
            if filename.endswith(".png") and f"leftImg8bit/{folder}/" in filename:
                with zip_ref.open(filename) as img_file:
                    img = cv2.imdecode(np.frombuffer(img_file.read(), np.uint8), cv2.IMREAD_COLOR)  # Load as color image
                    img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)
                    # --- Original Image ---
                    images.append(img)
                    count += 1

                    # --- Data Augmentation ---
                    # 1. Flipping
                    img_flipped = cv2.flip(img, 1)  # 1 for horizontal flip, 0 for vertical
                    images.append(img_flipped)
                    count += 1

                    # 2. Rotating
                    rows, cols = img.shape[:2]
                    angle = random.randint(-15, 15)  # Rotate by a random angle between -15 and 15 degrees

                    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
                    img_rotated = cv2.warpAffine(img, M, (cols, rows))
                    images.append(img_rotated)
                    count += 1

                    # 3. Adjusting Brightness
                    brightness_factor = random.uniform(0.7, 1.3)  # Adjust brightness by a factor between 0.7 and 1.3
                    img_brightened = cv2.addWeighted(img, brightness_factor, np.zeros(img.shape, img.dtype), 0, 0)
                    images.append(img_brightened)
                    count += 1

                    if count >= num_images:
                        break

    return np.array(images)

# Load Cityscapes training images from the zip file
x_train = load_cityscapes_images(zip_filepath, folder="train")
#x_val = load_cityscapes_images(zip_filepath, folder="val", num_images=1000)  # Adjust num_images as needed
# Load Cityscapes test images from the zip file
x_test = load_cityscapes_images(zip_filepath, folder="test")

# Preprocessing (for both x_train and x_test)
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0  # Preprocess x_test as well
#x_train = np.expand_dims(x_train, -1)  # Add channel dimension
#x_test = np.expand_dims(x_test, -1)  # Add channel dimension for x_test

# Noise functions
def add_poisson_noise(image):
    noisy_image = np.random.poisson(image * 255) / 255.0
    return noisy_image.clip(0, 1)

def add_gaussian_noise(image):
    mean = 0
    var = 0.01
    sigma = var ** 0.5
    gauss = np.random.normal(mean, sigma, image.shape)
    noisy_image = image + gauss
    return noisy_image.clip(0, 1)

def add_salt_and_pepper_noise(image):
    s_vs_p = 0.5
    amount = 0.05
    out = np.copy(image)
    # Salt mode
    num_salt = int(np.ceil(amount * image.size * s_vs_p))
    salt_coords = np.random.choice(out.size, size=num_salt, replace=False)
    out.flat[salt_coords] = 1

    # Pepper mode
    num_pepper = int(np.ceil(amount * image.size * (1. - s_vs_p)))
    pepper_coords = np.random.choice(out.size, size=num_pepper, replace=False)
    out.flat[pepper_coords] = 0
    return out

# Apply noise to the training set
x_train_noisy = np.array([
    add_gaussian_noise(img) if np.random.rand() < 0.5 else
    add_poisson_noise(img) if np.random.rand() < 0.5 else
    add_salt_and_pepper_noise(img)
    for img in x_train
])

# Visualize original and noisy images
def visualize_images(original, gaussian, poisson, sp, num_images=5):
    indices = random.sample(range(len(original)), num_images)
    fig, axes = plt.subplots(nrows=4, ncols=num_images, figsize=(15, 10))

    for i, idx in enumerate(indices):
        axes[0, i].imshow(original[idx])
        axes[0, i].set_title("Original")
        axes[0, i].axis('off')

        axes[1, i].imshow(gaussian[idx])
        axes[1, i].set_title("Gaussian")
        axes[1, i].axis('off')

        axes[2, i].imshow(poisson[idx])
        axes[2, i].set_title("Poisson")
        axes[2, i].axis('off')

        axes[3, i].imshow(sp[idx])
        axes[3, i].set_title("S&P")
        axes[3, i].axis('off')

    plt.tight_layout()
    plt.show()

# Generate noisy images for visualization
gaussian_noisy = np.array([add_gaussian_noise(img) for img in x_train])
poisson_noisy = np.array([add_poisson_noise(img) for img in x_train])
sp_noisy = np.array([add_salt_and_pepper_noise(img) for img in x_train])

# Visualize the images
visualize_images(x_train, gaussian_noisy, poisson_noisy, sp_noisy)

latent_dim = 64

#Encoder
encoder_inputs = keras.Input(shape=(128, 128, 3)) # Input shape matches Cityscapes color images
x = layers.Conv2D(32, 3, activation="relu", strides=2, padding="same")(encoder_inputs)
x = layers.Conv2D(64, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Conv2D(128, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Conv2D(256, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Conv2D(512, 3, activation="relu", strides=2, padding="same")(x)
x = layers.Flatten()(x)
x = layers.Reshape((-1,))(x)
x = layers.Dense(16, activation="relu")(x)
x = layers.Dropout(0.2)(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)

def sampling(args):
  z_mean, z_log_var = args
  batch_size = tf.shape(z_mean)[0]
  epsilon = tf.keras.backend.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)
  return z_mean + tf.keras.backend.exp(z_log_var / 2) * epsilon

z = layers.Lambda(sampling, name="z")([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
# In your encoder definition:
for layer in encoder.layers:
    print(layer.name, layer.output.shape)  # Use layer.output.shape

# Decoder

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(32 * 32 * 64, activation="leaky_relu")(latent_inputs)  # Adjusted for 128x128 input
x = layers.Reshape((32, 32, 64))(x)
x = layers.Conv2DTranspose(64, 3, activation="leaky_relu", strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(32, 3, activation="leaky_relu", strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.2)(x)
#x = layers.Conv2DTranspose(16, 3, activation="leaky_relu", strides=1, padding="same")(x)
#x = layers.BatchNormalization()(x)
#x = layers.Conv2DTranspose(8, 3, activation="leaky_relu", strides=1, padding="same")(x)
#x = layers.BatchNormalization()(x)
#x = layers.Conv2DTranspose(4, 3, activation="leaky_relu", strides=1, padding="same")(x)
#x = layers.BatchNormalization()(x)
decoder_outputs = layers.Conv2DTranspose(3, 3, activation="sigmoid", padding="same")(x) # Output shape matches Cityscapes color images

decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
encoder.summary()
decoder.summary()

class VAE(keras.Model):
    def __init__(self, encoder, decoder, learning_rate=0.0001, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.learning_rate = learning_rate

        # Metrics to track during training
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")

    @tf.function
    def call(self, inputs, training=False):
        z_mean, z_log_var, z = self.encoder(inputs, training=training)
        reconstruction = self.decoder(z, training=training)
        return reconstruction

    @tf.function
    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))

            # KL Loss Annealing
            beta_value = 0.01  # Example: Set beta to 0.05
            beta = tf.minimum(beta_value, tf.cast(self.optimizer.iterations, tf.float32) / 10000)

            total_loss = reconstruction_loss + beta * kl_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }

    def configure_optimizers(self):
        return keras.optimizers.RectifiedAdamW(learning_rate=self.learning_rate, weight_decay=0.004)

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]
vae = VAE(encoder, decoder)

# Function to visualize reconstructions and calculate PSMR and SSIM
def visualize_reconstructions(vae, images, num_images=5):
    indices = random.sample(range(len(images)), num_images)
    original_images = images[indices]
    reconstructed_images = vae.predict(original_images)

    fig, axes = plt.subplots(nrows=2, ncols=num_images, figsize=(15, 5))
    for i in range(num_images):
        orig_img = original_images[i].squeeze()
        recon_img = reconstructed_images[i].squeeze()

        # Calculate PSNR and SSIM (specify data_range)
        psnr_val = psnr(orig_img, recon_img, data_range=1.0)  # data_range=1.0 for float images in [0, 1]
        ssim_val = ssim(orig_img, recon_img, data_range=1.0, channel_axis=2)  # data_range=1.0 for float images in [0, 1]

        # Original image
        axes[0, i].imshow(orig_img)
        axes[0, i].set_title(f"Original")
        axes[0, i].axis('off')

        # Reconstructed image
        axes[1, i].imshow(recon_img)
        axes[1, i].set_title(f"Reconstructed\nPSNR: {psnr_val:.2f}, SSIM: {ssim_val:.2f}")
        axes[1, i].axis('off')

    plt.tight_layout()
    plt.show()

# Combine noisy and clean images for training
x_train_subset = x_train[:4000]  # Use the first 3000 images for training
x_train_noisy_subset = x_train_noisy[:4000]  # Use the first 3000 noisy images for training
x_train_combined = np.concatenate((x_train_subset, x_train_noisy_subset))

#optimizer = tf.optimizers.RectifiedAdam(learning_rate=1e-4)  # AdamW with weight decay
vae.compile()

epochs = 500
history = vae.fit(x_train_combined,epochs=epochs, batch_size=32,callbacks=[keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: visualize_reconstructions(vae, x_train_combined) if (epoch + 1) % 5 == 0 else None)])
# Save the trained model
vae.save('/content/drive/MyDrive/vae_cityscape_model_1209.keras')#, save_format="h5")  # Save to Google Drive

# Save the trained model
vae.save('/content/drive/MyDrive/vae_cityscape_model.keras')

# Plot ELBO, Reconstruction, and KL Divergence vs. Epoch
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.plot(history.history['loss'])
plt.title('ELBO (Total Loss)')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.subplot(1, 3, 2)
plt.plot(history.history['reconstruction_loss'])
plt.title('Reconstruction Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.subplot(1, 3, 3)
plt.plot(history.history['kl_loss'])
plt.title('KL Divergence')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.tight_layout()
plt.show()

# Apply noise to the test set
x_test_noisy = np.array([
    add_gaussian_noise(img) if np.random.rand() < 0.5 else
    add_poisson_noise(img) if np.random.rand() < 0.5 else
    add_salt_and_pepper_noise(img)
    for img in x_test
])

# Visualize original, noisy, and reconstructed images from the test set
def visualize_test_reconstructions(vae, original, noisy, num_images=5):
    indices = random.sample(range(len(original)), num_images)
    original_images = original[indices]
    noisy_images = noisy[indices]
    reconstructed_images = vae.predict(noisy_images)

    fig, axes = plt.subplots(nrows=3, ncols=num_images, figsize=(15, 10))
    for i in range(num_images):
        orig_img = original_images[i].squeeze()
        noisy_img = noisy_images[i].squeeze()
        recon_img = reconstructed_images[i].squeeze()

        # Calculate PSNR and SSIM
        psnr_val = psnr(orig_img, recon_img, data_range=1.0)
        ssim_val = ssim(orig_img, recon_img, data_range=1.0, channel_axis=2)

        # Original image
        axes[0, i].imshow(orig_img, cmap='gray')
        axes[0, i].set_title("Original")
        axes[0, i].axis('off')

        # Noisy image
        axes[1, i].imshow(noisy_img, cmap='gray')
        axes[1, i].set_title("Noisy")
        axes[1, i].axis('off')

        # Reconstructed image
        axes[2, i].imshow(recon_img, cmap='gray')
        axes[2, i].set_title(f"Reconstructed\nPSNR: {psnr_val:.2f}, SSIM: {ssim_val:.2f}")
        axes[2, i].axis('off')

    plt.tight_layout()
    plt.show()

# Visualize reconstructions from the test set
visualize_test_reconstructions(vae, x_test, x_test_noisy)

# In your encoder definition:
for layer in encoder.layers:
    print(layer.name, layer.output_shape)

import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

def denoise_image_from_drive(vae, filepath):
    """
    Loads an image from Google Drive, adds noise, denoises it using the VAE,
    and visualizes the results. Resizes the image to 128x128 for processing
    as the VAE is trained on 128x128 images. Calculates PSNR and SSIM at
    the 128x128 resolution. Outputs the denoised image at 128x128.
    """
    img = cv2.imread(filepath, cv2.IMREAD_COLOR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
    original_height, original_width = img.shape[:2]

    # Resize to 128x128 for VAE processing
    img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)
    img = img.astype("float32") / 255.0

    # Add noise to the image (replace with your add_gaussian_noise function)
    #noisy_img = add_gaussian_noise(img)
    noisy_img = img
    # Denoise the image using the VAE
    denoised_img = vae.predict(noisy_img[np.newaxis, ...])
    denoised_img = denoised_img[0]  # Remove batch dimension
    print("Denoised Image Shape:", denoised_img.shape)
    print("Sample Pixel Values:", denoised_img[0, 0, :])  # Print RGB values of the top-left pixel
    denoised_img = (denoised_img - np.min(denoised_img)) / (np.max(denoised_img) - np.min(denoised_img))
    cv2.imwrite("denoised_image.jpg", cv2.cvtColor(denoised_img * 255, cv2.COLOR_RGB2BGR)) # Convert back to BGR and scale to 0-255

    # Calculate PSNR and SSIM before resizing back
    psnr_val = psnr(img, denoised_img, data_range=1.0)
    ssim_val = ssim(img, denoised_img, data_range=1.0, channel_axis=2)

    # Visualize the results (denoised_img remains at 128x128)
    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(5, 10))

    # Original image (resized to 128x128)
    axes[0].imshow(img)
    axes[0].set_title("Original")
    axes[0].axis('off')

    # Noisy image
    axes[1].imshow(noisy_img)
    axes[1].set_title("Noisy")
    axes[1].axis('off')

    # Denoised image (128x128)
    axes[2].imshow(denoised_img)
    axes[2].set_title("Denoised")
    axes[2].axis('off')

    plt.show()

    print(f"PSNR: {psnr_val:.2f} dB")
    print(f"SSIM: {ssim_val:.4f}")

# Example usage (make sure you have your 'vae' object and 'add_gaussian_noise' function defined)
image_path = "/content/drive/MyDrive/japan.jpg"
denoise_image_from_drive(vae, image_path)

# Example usage:
image_path = "/content/drive/MyDrive/beach.png"  # Replace with the actual path to your image
img = cv2.imread("/content/drive/MyDrive/beach.png", cv2.IMREAD_COLOR)
if img is None:
    print(f"Error: Could not read image from {filepath}")

height, width, channels = img.shape

print(f"Image Dimensions: Height = {height}, Width = {width}, Channels = {channels}")
denoise_image_from_drive(vae, image_path)

